---
title: "Proj3"
author: "Durley Torres-Marin"
date: "October 17, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
suppressPackageStartupMessages(library('XML'))
suppressPackageStartupMessages(library('rvest'))
suppressPackageStartupMessages(library('tidyr'))
suppressPackageStartupMessages(library('ggplot2'))
```

```{r}
# Check if the package is installed. If not, install the package
if(!require('XML')) {
  install.packages('XML')
  library(XML)
#Loading XML package
}
```

```{r}
# Check if the package is installed. If not, install the package
if(!require('rvest')) {
  install.packages('rvest')
  library(rvest)
#Loading rvest package
}
```

```{r}
# Check if the package is installed. If not, install the package
if(!require('stringr')) {
  install.packages('stringr')
  library(stringr)
#Loading string package
}
```

```{r}
# Checking if packages needed are installed. If not, install the package
if(!require('tidyr')) {
  install.packages('tidyr')
  library(tidyr)
#Loading rvest package
}
```

```{r}
# Checking if packages needed are installed. If not, install the package
if(!require('ggplot2')) {
  install.packages('ggplot2')
  library(ggplot2)
#Loading rvest package
}
```

#Data Science Skills
W.Edward Deming said, "In God we trust, all others must bring data". --Please use data to answer the question "Which skills are the most valued data science skills?". Consider your work as an exploration, there is not necessarilly a "right answer".
####Giving a short introduction extracted from wikipedia.

```{r}
data.science <- read_html("https://en.wikipedia.org/wiki/Data_science")
data.science.html <- htmlTreeParse(data.science, useInternal = TRUE) 
data.science.text <- unlist(xpathApply(data.science.html, '//body', xmlValue))
gsub("\\[[0-9].+\\]", "", str_trim(str_extract(data.science.text, ".Data scientist. has become.+")))
```
![](C:\Users\Dora\Downloads\Data_Science_Process.PNG)

Data science process flowchart from "Doing Data Science", Cathy O'Neil and Rachel Schutt, 2013

```{r}
data.image <- data.science %>% 
  
  html_nodes(".thumbimage") %>%
  html_attr("src")
data.image
```

## Web Scrapping 

### Health Care Industry

####Methodology used: 
1. Access a web page from R using the package 'rvest'
2. Tell R where to look for the page providing an url
3. Manipulate the data in a usable format within R

####Job 1
```{r}
job1 <- read_html("https://cds.nyu.edu/junior-data-scientist-software-working-group/")
#Job title and quaifications(skills) extracted
job1.title <- job1 %>% html_nodes(".page-title") %>% html_text()

#Getting the skills 
job1.skills <- job1 %>% html_nodes("ul:nth-child(9) p") %>% html_text()
df1 <- data.frame(job1.title, job1.skills)
as.character(df1$job1.skills)
y <-unlist(strsplit(job1.skills, split = ",", fixed = TRUE))
x <- str_extract_all(df1$job1.title, "[:alpha:]+")

dfjob1 <- 
df1$job1.skills <- factor(df1$job1.skills)


# split the data base on each skill
ndf <- split(df1, df1$job1.skills)  

#df1$job1.title <- str_replace(df1$job1.title, ".\[a-z]\.", " ")
#job1.title<- str_extract_all(df1$job1.title, "\\w+[[:alpha:]].?\\w+")
y
```

###Job 2

```{r}
###Job 2
job2 <-read_html("https://job-openings.monster.com/Data-Scientist-OQPS-Albany-NY-US-PCG-Staffing-Solutions-Organization-LL/31/95cf1092-4b5f-4ffe-909f-dd5c1d30d6c7")
job2.title <- job2 %>% html_nodes("#JobViewHeader .title") %>% html_text()



#Getting the skills 
job2.skills<- job2 %>% html_nodes("ol:nth-child(6) li") %>% html_text()
df2 <- data.frame(job2.title, job2.skills)
as.character(df1$job2.skills)
y <-unlist(strsplit(job2.skills, split = ",", fixed = TRUE))

y
```

###Job3
```{r}
job3 <-read_html("http://www.respondhr.com/58118630")
job3.title <- job3 %>% html_nodes("#jobtitletext") %>% html_text()


#Getting the skills 
job3.skills <- job3 %>% html_nodes("ul:nth-child(7) li") %>% html_text()
df3 <- data.frame(job3.title, job3.skills)
as.character(df3$job3.skills)
y <-unlist(strsplit(job3.skills, split = ",", fixed = TRUE))

y

```

###Job4
```{r}
job4 <-read_html("https://jobs.smartrecruiters.com/4Catalyzer/743999661313585-data-scientist")
job4.title <- job4 %>% html_nodes(".job-title") %>% html_text()


#Getting the skills 
job4.skills <- job4 %>% html_nodes("ul:nth-child(2) p") %>% html_text()
df4 <- data.frame(job4.title,job4.skills)
as.character(df4$job4.skills)
y <-unlist(strsplit(job4.skills, split = ",", fixed = TRUE))

y

```
###Job 5
```{r}
job5 <-read_html("http://jobs.nyulangone.org/job/7733505/")
job5.title <- job5 %>% html_nodes("#gtm-jobdetail-title") %>% html_text()


#Getting the skills 
job5.skills <- job5 %>% html_nodes("p:nth-child(5)") %>% html_text()
df5 <- data.frame(job5.title,job5.skills)
as.character(df5$job5.skills)
y <-unlist(strsplit(job5.skills, split = ".", fixed = TRUE))
y <-unlist(strsplit(y, split = ",", fixed = TRUE))

y

```
```{r}
job.data <- read.csv("https://raw.githubusercontent.com/doradu8030/Data607/master/Clean%20Data.csv", stringsAsFactor = FALSE)
```
```{r eval=FALSE}
ggplot(data=dat1, aes(x= Skill.Type, y= Req))+ geom_bar(colour="black", width=.8, stat = "Identity", fill= "blue") + 
guides(fill=FALSE) + 
xlab("Skills") + ylab("count") + 
ggtitle("Comparison Between Hard and Soft Skill")     
``` 

```{r eval = FALSE}
ggplot(data=job.data, aes(x= Industry, y = Skill.Set)) + geom_bar(stat = "Identity", fill= "blue") + theme_bw(base_size = 16) + theme(axis.text = element_text(angle = 0, hjust = 1)) + coord_flip()
```

![](C:\Users\Dora\CUNY\DATA607-Data Acquisition\Project3\HCProj3.PNG)

####Difficulties.
1. One of most challenging parts from scrapping data was learn how to use CCS selector. It seems easy in the tutorials but I found this piece challenging for me, I spent too much time trying to select the correct tag. 
2. I scraped a a html page that couple of days after it was no longer available. It was time consuming do all process finding a new html page. 
3. Sometimes data are not downloadable, or dont' have tags for each piece of information, the data couldn't be scraped.
In my case I had to select only one source "Monster" and select the job posts individually due to each website has different format, and I found Monster easy especially the format used to tag a html page. 

####Conclusion.
I found scrapping data very powerful tool but It is not very easy to scrap data from different websites due to the terms of service in place and in the difference each html page is formated. However, Scrapping data form the web could provides very useful information to various organizations and industries especially Bussines companies. 
For our project, scrapping the data by industry and seeing my peers analysis allow me to conclude that in most of industries soft skills are NOT the most valued for jobs as a Data Scientist at the contrary hard skills (Technical Skills) are the most valued data science skills. 

